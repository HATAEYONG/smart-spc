"""
XGBoost ê¸°ë°˜ ê³µì • ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸
ì‹¤ì‹œê°„ ì‘ì—… íŠ¹ì„± ì…ë ¥ â†’ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ ì¶œë ¥ â†’ APS ìŠ¤ì¼€ì¤„ë§ ì…ë ¥ìœ¼ë¡œ í™œìš©
"""
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
import joblib
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class ProcessTimePredictorXGB:
    """
    XGBoost ê¸°ë°˜ ê³µì • ì‹œê°„ ì˜ˆì¸¡ê¸°
    """

    def __init__(self):
        self.model = None
        self.feature_names = None
        self.label_encoders = {}
        self.feature_importance = None

    def preprocess_data(self, df, fit=True):
        """
        ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¸ì½”ë”©

        Args:
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            fit: Trueë©´ LabelEncoder í•™ìŠµ, Falseë©´ ê¸°ì¡´ ì¸ì½”ë” ì‚¬ìš©

        Returns:
            X: íŠ¹ì„± ë°ì´í„°
            y: íƒ€ê²Ÿ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
        """
        df = df.copy()

        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_features = ['process_name', 'machine_id', 'item_type']

        for col in categorical_features:
            if fit:
                if col not in self.label_encoders:
                    self.label_encoders[col] = LabelEncoder()
                df[col] = self.label_encoders[col].fit_transform(df[col])
            else:
                if col in self.label_encoders:
                    # í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ ì¹´í…Œê³ ë¦¬ëŠ” -1ë¡œ ì²˜ë¦¬
                    df[col] = df[col].apply(
                        lambda x: self.label_encoders[col].transform([x])[0]
                        if x in self.label_encoders[col].classes_
                        else -1
                    )

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        if 'process_time_minutes' in df.columns:
            X = df.drop('process_time_minutes', axis=1)
            y = df['process_time_minutes']
            return X, y
        else:
            return df, None

    def train(self, data_path, test_size=0.2, random_state=42):
        """
        XGBoost ëª¨ë¸ í•™ìŠµ

        Args:
            data_path: í•™ìŠµ ë°ì´í„° CSV ê²½ë¡œ
            test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
            random_state: ëœë¤ ì‹œë“œ
        """
        print("ğŸ“š í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(data_path)
        print(f"   - ë°ì´í„° í¬ê¸°: {df.shape}")

        # ì „ì²˜ë¦¬
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        X, y = self.preprocess_data(df, fit=True)
        self.feature_names = X.columns.tolist()

        # Train-Test Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        print(f"   - í•™ìŠµ ì„¸íŠ¸: {X_train.shape[0]} ìƒ˜í”Œ")
        print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {X_test.shape[0]} ìƒ˜í”Œ")

        # XGBoost ëª¨ë¸ í•™ìŠµ
        print("\nğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=random_state,
            n_jobs=-1,
            objective='reg:squarederror'
        )

        # Early Stoppingì„ ìœ„í•œ í‰ê°€ ì„¸íŠ¸
        eval_set = [(X_train, y_train), (X_test, y_test)]

        self.model.fit(
            X_train, y_train,
            eval_set=eval_set,
            eval_metric='rmse',
            early_stopping_rounds=20,
            verbose=False
        )

        # ì˜ˆì¸¡ ë° í‰ê°€
        print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:")
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)

        # í•™ìŠµ ì„¸íŠ¸ ì„±ëŠ¥
        train_mae = mean_absolute_error(y_train, y_train_pred)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
        train_r2 = r2_score(y_train, y_train_pred)

        print(f"   [í•™ìŠµ ì„¸íŠ¸]")
        print(f"   - MAE: {train_mae:.2f} ë¶„")
        print(f"   - RMSE: {train_rmse:.2f} ë¶„")
        print(f"   - RÂ² Score: {train_r2:.4f}")

        # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥
        test_mae = mean_absolute_error(y_test, y_test_pred)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
        test_r2 = r2_score(y_test, y_test_pred)

        print(f"\n   [í…ŒìŠ¤íŠ¸ ì„¸íŠ¸]")
        print(f"   - MAE: {test_mae:.2f} ë¶„")
        print(f"   - RMSE: {test_rmse:.2f} ë¶„")
        print(f"   - RÂ² Score: {test_r2:.4f}")

        # íŠ¹ì„± ì¤‘ìš”ë„
        self.feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)

        print("\nğŸ” ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:")
        for idx, row in self.feature_importance.head(10).iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")

        return {
            'train_mae': train_mae,
            'train_rmse': train_rmse,
            'train_r2': train_r2,
            'test_mae': test_mae,
            'test_rmse': test_rmse,
            'test_r2': test_r2
        }

    def predict(self, job_features):
        """
        ì‘ì—… íŠ¹ì„± ì…ë ¥ â†’ ê³µì • ì‹œê°„ ì˜ˆì¸¡

        Args:
            job_features: dict ë˜ëŠ” DataFrame
                í•„ìˆ˜ íŠ¹ì„±:
                - process_name, machine_id, item_type
                - complexity, batch_size, operator_skill
                - shift, temperature, humidity
                - machine_age_days, maintenance_days_ago
                - has_previous_job, setup_time

        Returns:
            predicted_time: ì˜ˆì¸¡ëœ ê³µì • ì‹œê°„ (ë¶„)
            confidence_interval: 95% ì‹ ë¢°êµ¬ê°„ (í•˜í•œ, ìƒí•œ)
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train() ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        # DataFrameìœ¼ë¡œ ë³€í™˜
        if isinstance(job_features, dict):
            df = pd.DataFrame([job_features])
        else:
            df = job_features.copy()

        # job_id ì œê±° (ìˆëŠ” ê²½ìš°)
        if 'job_id' in df.columns:
            job_ids = df['job_id'].tolist()
            df = df.drop('job_id', axis=1)
        else:
            job_ids = None

        # ì „ì²˜ë¦¬
        X, _ = self.preprocess_data(df, fit=False)

        # íŠ¹ì„± ìˆœì„œ ë§ì¶”ê¸°
        X = X[self.feature_names]

        # ì˜ˆì¸¡
        predictions = self.model.predict(X)

        # ì‹ ë¢°êµ¬ê°„ ì¶”ì • (Bootstrap ë°©ì‹ì˜ ê°„ë‹¨í•œ ê·¼ì‚¬)
        # ì‹¤ì œë¡œëŠ” Quantile Regression ë˜ëŠ” Bootstrap ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” í…ŒìŠ¤íŠ¸ RMSEë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨íˆ ì¶”ì •
        std_error = 5.0  # í…ŒìŠ¤íŠ¸ RMSE ê·¼ì‚¬ê°’
        confidence_lower = predictions - 1.96 * std_error
        confidence_upper = predictions + 1.96 * std_error

        # ê²°ê³¼ ë°˜í™˜
        results = []
        for i, pred in enumerate(predictions):
            result = {
                'predicted_time_minutes': round(float(pred), 2),
                'confidence_interval_95': {
                    'lower': round(float(confidence_lower[i]), 2),
                    'upper': round(float(confidence_upper[i]), 2)
                }
            }
            if job_ids:
                result['job_id'] = job_ids[i]
            results.append(result)

        return results if len(results) > 1 else results[0]

    def save_model(self, model_dir='C:\\Claude\\online-aps-cps-scheduler\\backend\\ai_modules\\ml_models\\saved'):
        """
        ëª¨ë¸ ì €ì¥
        """
        Path(model_dir).mkdir(parents=True, exist_ok=True)

        # XGBoost ëª¨ë¸ ì €ì¥
        model_path = Path(model_dir) / 'xgboost_process_time_model.json'
        self.model.save_model(str(model_path))

        # ë©”íƒ€ë°ì´í„° ì €ì¥ (LabelEncoders, feature_names ë“±)
        meta_path = Path(model_dir) / 'model_metadata.pkl'
        metadata = {
            'feature_names': self.feature_names,
            'label_encoders': self.label_encoders,
            'feature_importance': self.feature_importance.to_dict('records')
        }
        joblib.dump(metadata, meta_path)

        print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_dir}")
        return model_path, meta_path

    def load_model(self, model_dir='C:\\Claude\\online-aps-cps-scheduler\\backend\\ai_modules\\ml_models\\saved'):
        """
        ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
        """
        model_path = Path(model_dir) / 'xgboost_process_time_model.json'
        meta_path = Path(model_dir) / 'model_metadata.pkl'

        # XGBoost ëª¨ë¸ ë¡œë“œ
        self.model = xgb.XGBRegressor()
        self.model.load_model(str(model_path))

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata = joblib.load(meta_path)
        self.feature_names = metadata['feature_names']
        self.label_encoders = metadata['label_encoders']
        self.feature_importance = pd.DataFrame(metadata['feature_importance'])

        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_dir}")
        return self

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: í•™ìŠµ â†’ í‰ê°€ â†’ ì €ì¥ â†’ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    """
    print("=" * 80)
    print("ğŸ¤– XGBoost ê³µì • ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("=" * 80)

    # ë°ì´í„° ê²½ë¡œ
    data_path = 'C:\\Claude\\online-aps-cps-scheduler\\backend\\ai_modules\\data\\process_time_training_data.csv'

    # ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
    predictor = ProcessTimePredictorXGB()
    metrics = predictor.train(data_path)

    # ëª¨ë¸ ì €ì¥
    predictor.save_model()

    # ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 80)
    print("ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # ìƒ˜í”Œ ì‘ì—… ë¡œë“œ
    sample_path = 'C:\\Claude\\online-aps-cps-scheduler\\backend\\ai_modules\\data\\sample_jobs.json'
    with open(sample_path, 'r', encoding='utf-8') as f:
        sample_jobs = json.load(f)

    print(f"\nğŸ“‹ {len(sample_jobs)}ê°œ ìƒ˜í”Œ ì‘ì—… ì˜ˆì¸¡ ì¤‘...\n")

    for job in sample_jobs:
        job_id = job['job_id']
        result = predictor.predict(job)

        print(f"ì‘ì—… ID: {job_id}")
        print(f"  ê³µì •: {job['process_name']} | ì„¤ë¹„: {job['machine_id']} | í’ˆëª©: {job['item_type']}")
        print(f"  ë³µì¡ë„: {job['complexity']} | ë°°ì¹˜: {job['batch_size']} | ìˆ™ë ¨ë„: {job['operator_skill']}")
        print(f"  ğŸ“Š ì˜ˆì¸¡ ì‹œê°„: {result['predicted_time_minutes']} ë¶„")
        print(f"  ğŸ“ˆ ì‹ ë¢°êµ¬ê°„(95%): [{result['confidence_interval_95']['lower']}, {result['confidence_interval_95']['upper']}] ë¶„")
        print()

    print("=" * 80)
    print("âœ… ëª¨ë¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)

    # ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥
    print("\nğŸ“š ì‚¬ìš© ì˜ˆì‹œ:")
    print("""
    # 1. ëª¨ë¸ ë¡œë“œ
    predictor = ProcessTimePredictorXGB()
    predictor.load_model()

    # 2. ì‘ì—… íŠ¹ì„± ì…ë ¥
    job = {
        'process_name': 'ê°€ê³µ',
        'machine_id': 'MC001',
        'item_type': 'í”„ë ˆì„',
        'complexity': 7,
        'batch_size': 50,
        'operator_skill': 4,
        'shift': 1,
        'temperature': 23.5,
        'humidity': 52.0,
        'machine_age_days': 730,
        'maintenance_days_ago': 15,
        'has_previous_job': 1,
        'setup_time': 10
    }

    # 3. ê³µì • ì‹œê°„ ì˜ˆì¸¡
    result = predictor.predict(job)
    print(f"ì˜ˆì¸¡ ì‹œê°„: {result['predicted_time_minutes']} ë¶„")

    # 4. APS ìŠ¤ì¼€ì¤„ë§ì— ì…ë ¥
    # â†’ ì´ ì˜ˆì¸¡ê°’ì„ APS ì•Œê³ ë¦¬ì¦˜ì˜ process_timeìœ¼ë¡œ ì‚¬ìš©
    """)

if __name__ == '__main__':
    main()
