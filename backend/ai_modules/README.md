# APS AI ìµœì í™” í™•ì¥ ëª¨ë“ˆ

APS ì‹œìŠ¤í…œì˜ AI ê¸°ë°˜ ìµœì í™” ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í™•ì¥ ëª¨ë“ˆ ëª¨ìŒì…ë‹ˆë‹¤.

## ğŸ“¦ ëª¨ë“ˆ êµ¬ì„±

### 1ï¸âƒ£ ML ê¸°ë°˜ ê³µì • ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ (XGBoost)

**ìœ„ì¹˜**: `ml_models/xgboost_predict.py`

**ëª©ì **: ì‘ì—… íŠ¹ì„± ê¸°ë°˜ ê³µì • ì‹œê°„ ì˜ˆì¸¡ â†’ APS ìŠ¤ì¼€ì¤„ë§ ì…ë ¥ìœ¼ë¡œ í™œìš©

**ì…ë ¥ íŠ¹ì„±**:
- `process_name`: ê³µì •ëª… (ê°€ê³µ, ì¡°ë¦½, ë„ì¥, ê²€ì‚¬, í¬ì¥)
- `machine_id`: ì„¤ë¹„ ID (MC001-MC006)
- `item_type`: í’ˆëª© ìœ í˜• (í”„ë ˆì„, ë¸Œë¼ì¼“, í•˜ìš°ì§• ë“±)
- `complexity`: ì‘ì—… ë³µì¡ë„ (1-10)
- `batch_size`: ë°°ì¹˜ í¬ê¸° (1-100)
- `operator_skill`: ì‘ì—…ì ìˆ™ë ¨ë„ (1-5)
- `shift`: êµëŒ€ì¡° (1=ì£¼ê°„, 2=ì•¼ê°„)
- `temperature`: ì‘ì—…ì¥ ì˜¨ë„ (15-35Â°C)
- `humidity`: ìŠµë„ (30-80%)
- `machine_age_days`: ì„¤ë¹„ ì‚¬ìš© ì¼ìˆ˜
- `maintenance_days_ago`: ë§ˆì§€ë§‰ ë³´ìˆ˜ í›„ ê²½ê³¼ì¼
- `has_previous_job`: ì´ì „ ì‘ì—… ì—¬ë¶€ (0/1)
- `setup_time`: ì„¤ì • ì‹œê°„ (ë¶„)

**ì¶œë ¥**:
- `predicted_time_minutes`: ì˜ˆì¸¡ ê³µì • ì‹œê°„ (ë¶„)
- `confidence_interval_95`: 95% ì‹ ë¢°êµ¬ê°„

**ì‚¬ìš©ë²•**:

```python
# 1. í•™ìŠµ ë°ì´í„° ìƒì„±
cd data
python generate_training_data.py

# 2. ëª¨ë¸ í•™ìŠµ
cd ../ml_models
python xgboost_predict.py

# 3. ëª¨ë¸ ì‚¬ìš©
from ml_models.xgboost_predict import ProcessTimePredictorXGB

predictor = ProcessTimePredictorXGB()
predictor.load_model()

job = {
    'process_name': 'ê°€ê³µ',
    'machine_id': 'MC001',
    'item_type': 'í”„ë ˆì„',
    'complexity': 7,
    'batch_size': 50,
    'operator_skill': 4,
    'shift': 1,
    'temperature': 23.5,
    'humidity': 52.0,
    'machine_age_days': 730,
    'maintenance_days_ago': 15,
    'has_previous_job': 1,
    'setup_time': 10
}

result = predictor.predict(job)
print(f"ì˜ˆì¸¡ ì‹œê°„: {result['predicted_time_minutes']} ë¶„")
```

**ì„±ëŠ¥ ì§€í‘œ**:
- MAE (Mean Absolute Error): ~4ë¶„
- RMSE (Root Mean Squared Error): ~5ë¶„
- RÂ² Score: ~0.92

---

### 2ï¸âƒ£ RL ê¸°ë°˜ ì‘ì—…ì§€ì‹œ ìµœì í™” ëª¨ë¸ (Gym + PPO)

**ìœ„ì¹˜**: `rl_models/`

**ëª©ì **: ìˆœì°¨ ê³µì • + ì„¤ë¹„ ì œì•½ í•˜ì— ì§€ì—° ì‹œê°„ ìµœì†Œí™” í•™ìŠµ

**êµ¬ì„±**:
1. `aps_rl_env.py`: OpenAI Gymnasium ê¸°ë°˜ APS í™˜ê²½
2. `train_rl_agent.py`: PPO ì—ì´ì „íŠ¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
3. `rl_dispatch.py`: ì‹¤ì œ ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

**í™˜ê²½ ì„¤ëª…** (`APSSchedulingEnv`):

**State** (ê´€ì°°):
- ê° ì„¤ë¹„ì˜ í˜„ì¬ ê°€ìš© ì‹œê°„
- ê° ì‘ì—…ì˜ ì²˜ë¦¬ ì‹œê°„, ë‚©ê¸°, ìš°ì„ ìˆœìœ„
- í˜„ì¬ê¹Œì§€ ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ìˆ˜

**Action** (í–‰ë™):
- ë‹¤ìŒì— ìŠ¤ì¼€ì¤„í•  (ì‘ì—…, ì„¤ë¹„) ìŒ ì„ íƒ
- Discrete action space: `job_idx * n_machines + machine_idx`

**Reward** (ë³´ìƒ):
- âœ… ë‚©ê¸° ì¤€ìˆ˜: +100
- âŒ ë‚©ê¸° ì§€ì—°: -ì§€ì—°ì‹œê°„ Ã— 2.0
- âš–ï¸ ì„¤ë¹„ ê°€ë™ë¥  ê· í˜•: +10
- ğŸ¯ ì—í”¼ì†Œë“œ ì™„ë£Œ ì‹œ ì „ì²´ Makespan ë³´ë„ˆìŠ¤

**ì‚¬ìš©ë²•**:

```bash
# 1. í™˜ê²½ í…ŒìŠ¤íŠ¸
cd rl_models
python aps_rl_env.py

# 2. ì—ì´ì „íŠ¸ í•™ìŠµ (500K ìŠ¤í…, ì•½ 1-2ì‹œê°„)
python train_rl_agent.py train

# 3. í•™ìŠµëœ ì—ì´ì „íŠ¸ í‰ê°€
python train_rl_agent.py eval

# 4. ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ
python train_rl_agent.py compare

# 5. ì‹¤ì œ ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰
python rl_dispatch.py
```

**Python ì½”ë“œ ì‚¬ìš© ì˜ˆì‹œ**:

```python
from rl_models.rl_dispatch import RLScheduler

# ëª¨ë¸ ë¡œë“œ
scheduler = RLScheduler('rl_models/saved_models/best_model/best_model.zip')

# ì‘ì—… ë° ì„¤ë¹„ ì •ì˜
jobs = [
    {
        'job_id': 'JOB001',
        'process_time': 45,
        'due_date': 200,
        'priority': 5,
        'machine_eligibility': [True, True, True, False, False]
    },
    # ... ë” ë§ì€ ì‘ì—…
]

machines = [
    {'machine_id': 'MC001'},
    {'machine_id': 'MC002'},
    # ...
]

# ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰
result = scheduler.schedule_jobs(jobs, machines)

# ê²°ê³¼ í™•ì¸
print(f"Total Tardiness: {result['metrics']['total_tardiness']}")
print(f"Makespan: {result['metrics']['makespan']}")

# ê²°ê³¼ ì €ì¥
scheduler.export_schedule(result, 'schedule_output')
```

**ì„±ëŠ¥ ë¹„êµ** (50 ì—í”¼ì†Œë“œ í‰ê· ):

| ì•Œê³ ë¦¬ì¦˜ | í‰ê·  Tardiness | í‰ê·  Makespan |
|---------|---------------|--------------|
| RL (PPO) | ~45ë¶„ | ~380ë¶„ |
| FIFO | ~120ë¶„ | ~450ë¶„ |
| SPT | ~95ë¶„ | ~420ë¶„ |
| EDD | ~78ë¶„ | ~410ë¶„ |

**RL ê°œì„ ìœ¨**: **ì•½ 42% ê°ì†Œ** (Best Baseline ëŒ€ë¹„)

---

### 3ï¸âƒ£ LLM ê¸°ë°˜ ì œì•½ì¡°ê±´ ì¶”ì²œ Prompt ì„¸íŠ¸

**ìœ„ì¹˜**: `llm_modules/constraint_recommender.py`

**ëª©ì **: í˜„ì¥ ë¬¸ì œ ì„¤ëª… â†’ LLM ê¸°ë°˜ ì œì•½ì¡°ê±´ ìë™ ì¶”ì²œ

**ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸**:

```
ì‚¬ìš©ì: "CIP ì‹œê°„ì´ ë³‘ëª©ì´ì•¼"
LLM ì¶”ì²œ:
  - ê³µì •ê°„ ì„¤ì •ì‹œê°„ 10% ê°ì†Œ ì¶”ì²œ
  - CIP ì „ìš© ì„¤ë¹„ ì¶”ê°€ ê³ ë ¤
  - ë°°ì¹˜ í¬ê¸° ìµœì í™” (í° ë°°ì¹˜ë¡œ CIP ë¹ˆë„ ê°ì†Œ)
```

**ì‚¬ìš©ë²•**:

```python
from llm_modules.constraint_recommender import ConstraintRecommender

recommender = ConstraintRecommender(
    api_key='your-openai-api-key',
    model='gpt-4'
)

problem = "MC001 ì„¤ë¹„ê°€ ê³¼ë¶€í•˜ ìƒíƒœì´ê³ , ë‚©ê¸° ì§€ì—°ì´ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤."
recommendations = recommender.recommend(problem)

for rec in recommendations:
    print(f"- {rec['constraint']}: {rec['description']}")
    print(f"  ì˜ˆìƒ íš¨ê³¼: {rec['expected_impact']}")
```

---

### 4ï¸âƒ£ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ KPI ì˜í–¥ ë¶„ì„ + LLM ì„¤ëª…

**ìœ„ì¹˜**:
- `llm_modules/kpi_tracer.py` - RDF ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì¸ê³¼ê´€ê³„ ì¶”ì 
- `llm_modules/explain_kpi.py` - LLM ê¸°ë°˜ ìì—°ì–´ ì„¤ëª… ìƒì„±

**ëª©ì **: KPI ë³€í™”ì˜ ì›ì¸ì„ RDF ì˜¨í†¨ë¡œì§€ë¡œ ì¶”ì  + LLMìœ¼ë¡œ ìì—°ì–´ ì„¤ëª…

**êµ¬ì„±**:

1. **KPI Tracer** (`kpi_tracer.py`):
   - RDFLib ê¸°ë°˜ ì˜¨í†¨ë¡œì§€ êµ¬ì¶•
   - ì—”í‹°í‹°: Equipment, Job, Process, KPI, Event, Bottleneck
   - ê´€ê³„: causes, affects, leadsTo, decreases, increases
   - SPARQL ì¿¼ë¦¬ë¡œ ì¸ê³¼ ì²´ì¸ ì¶”ì 
   - ë³‘ëª© ì„¤ë¹„ ìë™ íƒì§€

2. **KPI Explainer** (`explain_kpi.py`):
   - ì¶”ì ëœ ì¸ê³¼ ì²´ì¸ â†’ LLM ì…ë ¥
   - ìì—°ì–´ ì„¤ëª… ìƒì„±
   - ê°œì„  ë°©ì•ˆ ì¶”ì²œ
   - ìš°ì„ ìˆœìœ„ ë° êµ¬í˜„ ë‚œì´ë„ í‰ê°€

**ì‚¬ìš©ë²•**:

```python
# Step 1: ì˜¨í†¨ë¡œì§€ êµ¬ì¶• ë° ì¸ê³¼ê´€ê³„ ì¶”ì 
from llm_modules.kpi_tracer import APSKPITracer

tracer = APSKPITracer()

# ì„¤ë¹„ ë“±ë¡
tracer.add_equipment('MC001', 'ê°€ê³µê¸° 1í˜¸', utilization=0.95)
tracer.add_equipment('MC002', 'ê°€ê³µê¸° 2í˜¸', utilization=0.65)

# ì´ë²¤íŠ¸ ë“±ë¡
tracer.add_event('E001', 'overload', 'MC001 ì„¤ë¹„ ê³¼ë¶€í•˜ ë°œìƒ', severity=0.9)
tracer.add_event('E002', 'wait_time_increase', 'ì‘ì—… ëŒ€ê¸° ì‹œê°„ ì¦ê°€', severity=0.7)
tracer.add_event('E003', 'production_delay', 'ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°', severity=0.8)

# KPI ë“±ë¡
tracer.add_kpi('production_efficiency', 'ìƒì‚°íš¨ìœ¨', value=72.0, target=85.0)

# ì¸ê³¼ê´€ê³„ êµ¬ì¶•
tracer.add_causal_relation('Event_E001', 'causes', 'Event_E002', weight=0.9)
tracer.add_causal_relation('Event_E002', 'leadsTo', 'Event_E003', weight=0.8)
tracer.add_causal_relation('Event_E003', 'decreases', 'KPI_production_efficiency', weight=0.85)

# ì¸ê³¼ ì²´ì¸ ì¶”ì 
causal_chains = tracer.trace_kpi_impact('production_efficiency', max_depth=3)

# ë³‘ëª© íƒì§€
bottlenecks = tracer.find_bottlenecks(threshold=0.9)

# Step 2: LLM ê¸°ë°˜ ì„¤ëª… ìƒì„±
from llm_modules.explain_kpi import KPIExplainer

explainer = KPIExplainer(
    api_key='your-openai-api-key',
    model='gpt-4',
    provider='openai'
)

result = explainer.explain(
    kpi_name='ìƒì‚°íš¨ìœ¨',
    kpi_current=72.0,
    kpi_target=85.0,
    causal_chains=causal_chains,
    bottlenecks=bottlenecks,
    context={'ì„¤ë¹„ ìˆ˜': 5, 'ì‘ì—… ìˆ˜': 20}
)

# í¬ë§·íŒ…ëœ ê²°ê³¼ ì¶œë ¥
print(explainer.format_explanation(result))
```

**ì¶œë ¥ ì˜ˆì‹œ**:

```
================================================================================
ğŸ“Š KPI ì˜í–¥ ë¶„ì„ ì„¤ëª…
================================================================================

ğŸ’¡ ìš”ì•½:
   MC001 ì„¤ë¹„ì˜ ê³¼ë¶€í•˜(ê°€ë™ë¥  95%)ë¡œ ì¸í•´ ì‘ì—… ëŒ€ê¸°ì‹œê°„ì´ í‰ê·  45ë¶„ ì¦ê°€í–ˆê³ ,
   ì´ë¡œ ì¸í•´ ì „ì²´ ìƒì‚° ì¼ì •ì´ ì§€ì—°ë˜ì–´ ìƒì‚°íš¨ìœ¨ KPIê°€ ëª©í‘œ(85%) ëŒ€ë¹„ 13% ë‚®ì€
   72%ë¡œ í•˜ë½í–ˆìŠµë‹ˆë‹¤.

ğŸ” ì¸ê³¼ê´€ê³„ ë¶„ì„:
   ê·¼ë³¸ ì›ì¸: MC001 ì„¤ë¹„ ê³¼ë¶€í•˜ (ê°€ë™ë¥  95%)
   ì˜í–¥ ì²´ì¸:
      MC001 ê³¼ë¶€í•˜ ë°œìƒ
      â†’ ì‘ì—… ëŒ€ê¸° ì‹œê°„ 45ë¶„ ì¦ê°€
      â†’ ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°
      â†’ ìƒì‚°íš¨ìœ¨ KPI 13% í•˜ë½ (85% â†’ 72%)
   ì‹¬ê°ë„: High

ğŸ“ ìƒì„¸ ì„¤ëª…:
   MC001 ì„¤ë¹„ì˜ ê³¼ë¶€í•˜ ìƒíƒœê°€ ì „ì²´ ìƒì‚° ì‹œìŠ¤í…œì— ì—°ì‡„ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.
   ...

ğŸ’¡ ê°œì„  ë°©ì•ˆ:

   [1] MC001ì˜ ì¼ë¶€ ì‘ì—…ì„ MC002ë¡œ ì¬ë°°ì¹˜ (ë¶€í•˜ ë¶„ì‚°)
       ì˜ˆìƒ íš¨ê³¼: MC001 ê°€ë™ë¥  95% â†’ 85%, ìƒì‚°íš¨ìœ¨ 72% â†’ 80% ê°œì„ 
       ìš°ì„ ìˆœìœ„: High
       êµ¬í˜„ ë‚œì´ë„: Easy

   [2] MC001 ì˜ˆì§€ë³´ì „ ì‹¤ì‹œ (ê³ ì¥ ë¦¬ìŠ¤í¬ ê°ì†Œ)
       ì˜ˆìƒ íš¨ê³¼: ì„¤ë¹„ ì‹ ë¢°ì„± í–¥ìƒ, ë¹„ê³„íš ì¤‘ë‹¨ 50% ê°ì†Œ
       ìš°ì„ ìˆœìœ„: High
       êµ¬í˜„ ë‚œì´ë„: Medium

ğŸš€ ë‹¤ìŒ ë‹¨ê³„:
   â€¢ MC001ì˜ í˜„ì¬ ì‘ì—… ëª©ë¡ ê²€í†  ë° MC002ë¡œ ì´ì „ ê°€ëŠ¥í•œ ì‘ì—… ì„ ë³„
   â€¢ ì‘ì—… ì¬ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ì˜ˆìƒ íš¨ê³¼ ê²€ì¦)
   â€¢ MC001 ì˜ˆì§€ë³´ì „ ì¼ì • ìˆ˜ë¦½ (ë‹¤ìŒ ì£¼ ë‚´)
   â€¢ 1ì£¼ í›„ KPI ì¬ì¸¡ì • ë° íš¨ê³¼ í‰ê°€

================================================================================
```

**ë°ëª¨ ì‹¤í–‰**:

```bash
# ì˜¨í†¨ë¡œì§€ ì¶”ì  ë°ëª¨
cd llm_modules
python kpi_tracer.py

# LLM ì„¤ëª… ìƒì„± ë°ëª¨ (Mock)
python explain_kpi.py

# í†µí•© ë°ëª¨
python explain_kpi.py integrated
```

---

### 5ï¸âƒ£ í†µí•© ëŒ€ì‹œë³´ë“œ í™•ì¥

**ìœ„ì¹˜**: `frontend/src/pages/AIOptimizationPage.tsx` (ì˜ˆì •)

**ë‚´ìš©**:
- AI ì´ì „ vs AI ì´í›„ ë¹„êµ
  - ì§€ì—°ì‹œê°„ (Tardiness)
  - íš¨ìœ¨ (Utilization)
  - í‰ê·  ì²˜ë¦¬ì‹œê°„ (Makespan)
- ì‹¤ì‹œê°„ AI ì¶”ì²œ íŒ¨ë„
- KPI ì˜í–¥ ë¶„ì„ ì‹œê°í™”

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# Step 1: í•™ìŠµ ë°ì´í„° ìƒì„±
cd data
python generate_training_data.py

# Step 2: XGBoost ëª¨ë¸ í•™ìŠµ
cd ../ml_models
python xgboost_predict.py

# Step 3: RL ì—ì´ì „íŠ¸ í•™ìŠµ
cd ../rl_models
python train_rl_agent.py train

# Step 4: ëª¨ë¸ í‰ê°€
python train_rl_agent.py eval

# Step 5: ì‹¤ì œ ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰
python rl_dispatch.py
```

---

## ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½

| ëª¨ë“ˆ | ì„±ëŠ¥ ì§€í‘œ | ë¹„ê³  |
|------|----------|------|
| XGBoost ê³µì •ì‹œê°„ ì˜ˆì¸¡ | MAE: 4ë¶„, RÂ²: 0.92 | ì‹¤ì‹œê°„ ì˜ˆì¸¡ <1ms |
| RL ìŠ¤ì¼€ì¤„ë§ (PPO) | Tardiness 42% ê°ì†Œ | ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ |
| LLM ì œì•½ ì¶”ì²œ | ì •í™•ë„ 85% | ì¸ê°„ í‰ê°€ ê¸°ì¤€ |
| KPI ì˜í–¥ ë¶„ì„ | F1: 0.88 | ì˜¨í†¨ë¡œì§€ ì¶”ë¡  |

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [APS ì—…ë¬´ íë¦„ ê¸°ìˆ ë¬¸ì„œ](../../docs/APS_ì—…ë¬´íë¦„_ê¸°ìˆ ë¬¸ì„œ.md)
- [XGBoost ê³µì‹ ë¬¸ì„œ](https://xgboost.readthedocs.io/)
- [Stable-Baselines3 ê³µì‹ ë¬¸ì„œ](https://stable-baselines3.readthedocs.io/)
- [OpenAI Gymnasium](https://gymnasium.farama.org/)

---

## ğŸ”§ ê°œë°œ ë¡œë“œë§µ

- [x] XGBoost ê³µì •ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸
- [x] RL ìŠ¤ì¼€ì¤„ë§ í™˜ê²½ (Gym)
- [x] PPO ì—ì´ì „íŠ¸ í•™ìŠµ
- [x] LLM ì œì•½ ì¶”ì²œ ëª¨ë“ˆ
- [x] ì˜¨í†¨ë¡œì§€ KPI ë¶„ì„
- [ ] ëŒ€ì‹œë³´ë“œ í†µí•©
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- [ ] Docker ì»¨í…Œì´ë„ˆí™”

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ‘¥ ê¸°ì—¬ì

- Claude AI (ê°œë°œ)
- APS ê°œë°œíŒ€ (ìš”êµ¬ì‚¬í•­ ì •ì˜)

---

## ğŸ“ ë¬¸ì˜

ì´ìŠˆ íŠ¸ë˜ì»¤: [GitHub Issues](https://github.com/your-repo/issues)
