"""
ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ KPI ì˜í–¥ ë¶„ì„ ëª¨ë“ˆ
RDF ê·¸ë˜í”„ë¡œ ì¸ê³¼ê´€ê³„ ì¶”ì  + SPARQL ì¿¼ë¦¬
"""
from rdflib import Graph, Namespace, Literal, URIRef
from rdflib.namespace import RDF, RDFS, OWL, XSD
from typing import List, Dict, Tuple, Optional
import json
from pathlib import Path
from datetime import datetime


class APSKPITracer:
    """
    APS ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ KPI ì˜í–¥ ë¶„ì„ ì‹œìŠ¤í…œ
    """

    def __init__(self):
        """
        ì´ˆê¸°í™” ë° ì˜¨í†¨ë¡œì§€ êµ¬ì¶•
        """
        # RDF ê·¸ë˜í”„ ìƒì„±
        self.graph = Graph()

        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.APS = Namespace("http://aps-system.com/ontology#")
        self.graph.bind("aps", self.APS)
        self.graph.bind("rdf", RDF)
        self.graph.bind("rdfs", RDFS)
        self.graph.bind("owl", OWL)

        # ì˜¨í†¨ë¡œì§€ êµ¬ì¶•
        self._build_ontology()

    def _build_ontology(self):
        """
        APS ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ êµ¬ì¶•
        """
        # í´ë˜ìŠ¤ ì •ì˜
        classes = [
            'Equipment',      # ì„¤ë¹„
            'Job',           # ì‘ì—…
            'Process',       # ê³µì •
            'KPI',           # KPI ì§€í‘œ
            'Event',         # ì´ë²¤íŠ¸
            'Constraint',    # ì œì•½ì¡°ê±´
            'Resource',      # ìì›
            'Bottleneck'     # ë³‘ëª©
        ]

        for cls in classes:
            class_uri = self.APS[cls]
            self.graph.add((class_uri, RDF.type, OWL.Class))
            self.graph.add((class_uri, RDFS.label, Literal(cls)))

        # í”„ë¡œí¼í‹° ì •ì˜
        properties = {
            'causes': ('ì›ì¸ì´ ëœë‹¤', 'Event', 'Event'),
            'affects': ('ì˜í–¥ì„ ì¤€ë‹¤', 'Event', 'KPI'),
            'leadsTo': ('ì´ì–´ì§„ë‹¤', 'Event', 'Event'),
            'dependsOn': ('ì˜ì¡´í•œë‹¤', 'Process', 'Equipment'),
            'hasBottleneck': ('ë³‘ëª©ì„ ê°€ì§„ë‹¤', 'Equipment', 'Bottleneck'),
            'decreases': ('ê°ì†Œì‹œí‚¨ë‹¤', 'Event', 'KPI'),
            'increases': ('ì¦ê°€ì‹œí‚¨ë‹¤', 'Event', 'KPI'),
            'blockedBy': ('ì°¨ë‹¨ëœë‹¤', 'Job', 'Event'),
            'delaysJob': ('ì‘ì—…ì„ ì§€ì—°ì‹œí‚¨ë‹¤', 'Event', 'Job'),
            'utilizationOf': ('ê°€ë™ë¥ ', 'Equipment', 'KPI'),
            'tardinessOf': ('ì§€ì—°ì‹œê°„', 'Job', 'KPI'),
            'makespanOf': ('ì´ ì™„ë£Œì‹œê°„', 'Process', 'KPI')
        }

        for prop, (label, domain, range_) in properties.items():
            prop_uri = self.APS[prop]
            self.graph.add((prop_uri, RDF.type, OWL.ObjectProperty))
            self.graph.add((prop_uri, RDFS.label, Literal(label, lang='ko')))
            self.graph.add((prop_uri, RDFS.domain, self.APS[domain]))
            self.graph.add((prop_uri, RDFS.range, self.APS[range_]))

    def add_event(
        self,
        event_id: str,
        event_type: str,
        description: str,
        timestamp: Optional[datetime] = None,
        severity: float = 0.5
    ):
        """
        ì´ë²¤íŠ¸ ì¶”ê°€

        Args:
            event_id: ì´ë²¤íŠ¸ ID
            event_type: ì´ë²¤íŠ¸ ìœ í˜• (ì˜ˆ: 'overload', 'delay', 'failure')
            description: ì„¤ëª…
            timestamp: ë°œìƒ ì‹œê°„
            severity: ì‹¬ê°ë„ (0.0~1.0)
        """
        event_uri = self.APS[f"Event_{event_id}"]
        self.graph.add((event_uri, RDF.type, self.APS.Event))
        self.graph.add((event_uri, self.APS.eventType, Literal(event_type)))
        self.graph.add((event_uri, self.APS.description, Literal(description, lang='ko')))
        self.graph.add((event_uri, self.APS.severity, Literal(severity, datatype=XSD.float)))

        if timestamp:
            self.graph.add((event_uri, self.APS.timestamp, Literal(timestamp, datatype=XSD.dateTime)))

    def add_kpi(self, kpi_id: str, kpi_name: str, value: float, target: float):
        """
        KPI ì¶”ê°€

        Args:
            kpi_id: KPI ID
            kpi_name: KPI ì´ë¦„ (ì˜ˆ: 'production_efficiency', 'tardiness')
            value: í˜„ì¬ ê°’
            target: ëª©í‘œ ê°’
        """
        kpi_uri = self.APS[f"KPI_{kpi_id}"]
        self.graph.add((kpi_uri, RDF.type, self.APS.KPI))
        self.graph.add((kpi_uri, self.APS.kpiName, Literal(kpi_name)))
        self.graph.add((kpi_uri, self.APS.value, Literal(value, datatype=XSD.float)))
        self.graph.add((kpi_uri, self.APS.target, Literal(target, datatype=XSD.float)))
        self.graph.add((kpi_uri, self.APS.deviation, Literal(value - target, datatype=XSD.float)))

    def add_equipment(self, equipment_id: str, equipment_name: str, utilization: float):
        """
        ì„¤ë¹„ ì¶”ê°€

        Args:
            equipment_id: ì„¤ë¹„ ID (ì˜ˆ: 'MC001')
            equipment_name: ì„¤ë¹„ ì´ë¦„
            utilization: ê°€ë™ë¥  (0.0~1.0)
        """
        equipment_uri = self.APS[f"Equipment_{equipment_id}"]
        self.graph.add((equipment_uri, RDF.type, self.APS.Equipment))
        self.graph.add((equipment_uri, self.APS.equipmentId, Literal(equipment_id)))
        self.graph.add((equipment_uri, self.APS.equipmentName, Literal(equipment_name, lang='ko')))
        self.graph.add((equipment_uri, self.APS.utilization, Literal(utilization, datatype=XSD.float)))

    def add_causal_relation(
        self,
        source_id: str,
        relation: str,
        target_id: str,
        weight: float = 1.0
    ):
        """
        ì¸ê³¼ê´€ê³„ ì¶”ê°€

        Args:
            source_id: ì›ì¸ ì—”í‹°í‹° ID (Event, Equipment ë“±)
            relation: ê´€ê³„ ìœ í˜• ('causes', 'affects', 'leadsTo', 'decreases', 'increases')
            target_id: ê²°ê³¼ ì—”í‹°í‹° ID
            weight: ì˜í–¥ ê°€ì¤‘ì¹˜ (0.0~1.0)
        """
        # IDë¡œë¶€í„° URI ì¶”ë¡ 
        source_uri = self._infer_uri(source_id)
        target_uri = self._infer_uri(target_id)
        relation_uri = self.APS[relation]

        self.graph.add((source_uri, relation_uri, target_uri))
        self.graph.add((source_uri, self.APS.impactWeight, Literal(weight, datatype=XSD.float)))

    def _infer_uri(self, entity_id: str) -> URIRef:
        """
        ì—”í‹°í‹° IDë¡œë¶€í„° URI ì¶”ë¡ 
        """
        if entity_id.startswith('MC'):
            return self.APS[f"Equipment_{entity_id}"]
        elif entity_id.startswith('JOB'):
            return self.APS[f"Job_{entity_id}"]
        elif entity_id.startswith('KPI'):
            return self.APS[f"KPI_{entity_id}"]
        elif entity_id.startswith('Event'):
            return self.APS[entity_id]
        else:
            # ê¸°ë³¸ê°’
            return self.APS[entity_id]

    def trace_kpi_impact(self, kpi_id: str, max_depth: int = 5) -> List[Dict]:
        """
        KPI ë³€í™”ì˜ ì¸ê³¼ ì²´ì¸ ì¶”ì 

        Args:
            kpi_id: ì¶”ì í•  KPI ID
            max_depth: ìµœëŒ€ ì¶”ì  ê¹Šì´

        Returns:
            ì¸ê³¼ ì²´ì¸ ë¦¬ìŠ¤íŠ¸: [{'source': ..., 'relation': ..., 'target': ..., 'depth': ...}, ...]
        """
        kpi_uri = self.APS[f"KPI_{kpi_id}"]
        causal_chains = []

        # SPARQL ì¿¼ë¦¬: KPIì— ì˜í–¥ì„ ì£¼ëŠ” ì´ë²¤íŠ¸ ì°¾ê¸°
        query = f"""
        PREFIX aps: <{self.APS}>
        PREFIX rdf: <{RDF}>

        SELECT ?event ?relation ?description ?severity
        WHERE {{
            ?event ?relation aps:KPI_{kpi_id} .
            ?event aps:description ?description .
            ?event aps:severity ?severity .
            FILTER (?relation = aps:affects || ?relation = aps:decreases || ?relation = aps:increases)
        }}
        ORDER BY DESC(?severity)
        """

        results = self.graph.query(query)

        for row in results:
            event_uri = row.event
            relation = row.relation
            description = row.description
            severity = float(row.severity)

            # ì´ë²¤íŠ¸ì˜ ì›ì¸ ì¶”ì  (ì¬ê·€ì )
            root_causes = self._trace_event_causes(event_uri, depth=0, max_depth=max_depth)

            causal_chains.append({
                'event': str(event_uri).split('#')[-1],
                'relation': str(relation).split('#')[-1],
                'description': str(description),
                'severity': severity,
                'root_causes': root_causes
            })

        return causal_chains

    def _trace_event_causes(
        self,
        event_uri: URIRef,
        depth: int,
        max_depth: int
    ) -> List[Dict]:
        """
        ì´ë²¤íŠ¸ì˜ ê·¼ë³¸ ì›ì¸ ì¬ê·€ ì¶”ì 
        """
        if depth >= max_depth:
            return []

        # SPARQL ì¿¼ë¦¬: ì´ë²¤íŠ¸ì˜ ì›ì¸ ì°¾ê¸°
        query = f"""
        PREFIX aps: <{self.APS}>

        SELECT ?cause ?relation ?description
        WHERE {{
            ?cause ?relation <{event_uri}> .
            ?cause aps:description ?description .
            FILTER (?relation = aps:causes || ?relation = aps:leadsTo)
        }}
        """

        results = self.graph.query(query)
        causes = []

        for row in results:
            cause_uri = row.cause
            relation = row.relation
            description = row.description

            # ì¬ê·€ì ìœ¼ë¡œ ì›ì¸ ì¶”ì 
            sub_causes = self._trace_event_causes(cause_uri, depth + 1, max_depth)

            causes.append({
                'cause': str(cause_uri).split('#')[-1],
                'relation': str(relation).split('#')[-1],
                'description': str(description),
                'depth': depth + 1,
                'sub_causes': sub_causes
            })

        return causes

    def find_bottlenecks(self, threshold: float = 0.9) -> List[Dict]:
        """
        ë³‘ëª© ì„¤ë¹„ íƒì§€

        Args:
            threshold: ê°€ë™ë¥  ì„ê³„ê°’ (ê¸°ë³¸ 0.9 = 90%)

        Returns:
            ë³‘ëª© ì„¤ë¹„ ë¦¬ìŠ¤íŠ¸
        """
        query = f"""
        PREFIX aps: <{self.APS}>
        PREFIX xsd: <{XSD}>

        SELECT ?equipment ?equipmentId ?utilization
        WHERE {{
            ?equipment rdf:type aps:Equipment .
            ?equipment aps:equipmentId ?equipmentId .
            ?equipment aps:utilization ?utilization .
            FILTER (?utilization >= {threshold})
        }}
        ORDER BY DESC(?utilization)
        """

        results = self.graph.query(query)
        bottlenecks = []

        for row in results:
            bottlenecks.append({
                'equipment_id': str(row.equipmentId),
                'utilization': float(row.utilization),
                'severity': min(1.0, (float(row.utilization) - threshold) / (1.0 - threshold))
            })

        return bottlenecks

    def export_graph(self, output_path: str, format: str = 'turtle'):
        """
        RDF ê·¸ë˜í”„ ë‚´ë³´ë‚´ê¸°

        Args:
            output_path: ì €ì¥ ê²½ë¡œ
            format: í¬ë§· ('turtle', 'xml', 'json-ld')
        """
        self.graph.serialize(destination=output_path, format=format, encoding='utf-8')
        print(f"âœ… RDF ê·¸ë˜í”„ ì €ì¥: {output_path} (format: {format})")

    def import_graph(self, input_path: str, format: str = 'turtle'):
        """
        RDF ê·¸ë˜í”„ ë¶ˆëŸ¬ì˜¤ê¸°

        Args:
            input_path: íŒŒì¼ ê²½ë¡œ
            format: í¬ë§· ('turtle', 'xml', 'json-ld')
        """
        self.graph.parse(input_path, format=format)
        print(f"âœ… RDF ê·¸ë˜í”„ ë¡œë“œ: {input_path}")


def create_example_scenario():
    """
    ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±: MC001 ê³¼ë¶€í•˜ â†’ ìƒì‚° ì§€ì—° â†’ KPI ê°ì†Œ
    """
    print("=" * 80)
    print("ğŸ§ª KPI ì˜í–¥ ë¶„ì„ ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤")
    print("=" * 80)

    tracer = APSKPITracer()

    # 1. ì„¤ë¹„ ì¶”ê°€
    print("\nğŸ“¦ ì„¤ë¹„ ë“±ë¡...")
    tracer.add_equipment('MC001', 'ê°€ê³µê¸° 1í˜¸', utilization=0.95)
    tracer.add_equipment('MC002', 'ê°€ê³µê¸° 2í˜¸', utilization=0.65)
    tracer.add_equipment('MC003', 'ì¡°ë¦½ê¸° 1í˜¸', utilization=0.75)

    # 2. ì´ë²¤íŠ¸ ì¶”ê°€
    print("ğŸ“… ì´ë²¤íŠ¸ ë“±ë¡...")
    tracer.add_event(
        'E001',
        'overload',
        'MC001 ì„¤ë¹„ ê³¼ë¶€í•˜ ë°œìƒ (ê°€ë™ë¥  95%)',
        timestamp=datetime.now(),
        severity=0.9
    )

    tracer.add_event(
        'E002',
        'wait_time_increase',
        'ì‘ì—… ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (í‰ê·  45ë¶„)',
        timestamp=datetime.now(),
        severity=0.7
    )

    tracer.add_event(
        'E003',
        'production_delay',
        'ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°',
        timestamp=datetime.now(),
        severity=0.8
    )

    # 3. KPI ì¶”ê°€
    print("ğŸ“Š KPI ë“±ë¡...")
    tracer.add_kpi(
        'production_efficiency',
        'ìƒì‚°íš¨ìœ¨',
        value=72.0,  # í˜„ì¬ 72%
        target=85.0  # ëª©í‘œ 85%
    )

    tracer.add_kpi(
        'total_tardiness',
        'ì´ ì§€ì—°ì‹œê°„',
        value=180.0,  # í˜„ì¬ 180ë¶„
        target=60.0   # ëª©í‘œ 60ë¶„
    )

    # 4. ì¸ê³¼ê´€ê³„ ì¶”ê°€
    print("ğŸ”— ì¸ê³¼ê´€ê³„ êµ¬ì¶•...")

    # MC001 ê³¼ë¶€í•˜ â†’ ëŒ€ê¸°ì‹œê°„ ì¦ê°€
    tracer.add_causal_relation('Event_E001', 'causes', 'Event_E002', weight=0.9)

    # ëŒ€ê¸°ì‹œê°„ ì¦ê°€ â†’ ìƒì‚° ì§€ì—°
    tracer.add_causal_relation('Event_E002', 'leadsTo', 'Event_E003', weight=0.8)

    # ìƒì‚° ì§€ì—° â†’ ìƒì‚°íš¨ìœ¨ KPI ê°ì†Œ
    tracer.add_causal_relation('Event_E003', 'decreases', 'KPI_production_efficiency', weight=0.85)

    # ìƒì‚° ì§€ì—° â†’ ì§€ì—°ì‹œê°„ KPI ì¦ê°€
    tracer.add_causal_relation('Event_E003', 'increases', 'KPI_total_tardiness', weight=0.9)

    # 5. ì¸ê³¼ ì²´ì¸ ì¶”ì 
    print("\nğŸ” KPI ì˜í–¥ ë¶„ì„ (ìƒì‚°íš¨ìœ¨)...")
    causal_chains = tracer.trace_kpi_impact('production_efficiency', max_depth=3)

    print(f"\në°œê²¬ëœ ì¸ê³¼ ì²´ì¸: {len(causal_chains)}ê°œ")
    for i, chain in enumerate(causal_chains, 1):
        print(f"\n[ì²´ì¸ {i}]")
        print(f"  ì´ë²¤íŠ¸: {chain['event']}")
        print(f"  ì„¤ëª…: {chain['description']}")
        print(f"  ê´€ê³„: {chain['relation']}")
        print(f"  ì‹¬ê°ë„: {chain['severity']:.2f}")

        if chain['root_causes']:
            print(f"  ê·¼ë³¸ ì›ì¸:")
            for cause in chain['root_causes']:
                print(f"    â†’ {cause['description']} (depth: {cause['depth']})")
                if cause['sub_causes']:
                    for sub in cause['sub_causes']:
                        print(f"      â†’ {sub['description']} (depth: {sub['depth']})")

    # 6. ë³‘ëª© íƒì§€
    print("\nâš ï¸  ë³‘ëª© ì„¤ë¹„ íƒì§€...")
    bottlenecks = tracer.find_bottlenecks(threshold=0.9)

    for bottleneck in bottlenecks:
        print(f"  â€¢ {bottleneck['equipment_id']}: ê°€ë™ë¥  {bottleneck['utilization']*100:.1f}% (ì‹¬ê°ë„: {bottleneck['severity']:.2f})")

    # 7. ê·¸ë˜í”„ ì €ì¥
    output_path = Path(__file__).parent / 'kpi_analysis_example.ttl'
    tracer.export_graph(str(output_path), format='turtle')

    print("\n" + "=" * 80)
    print("âœ… ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ!")
    print("=" * 80)

    return tracer, causal_chains, bottlenecks


if __name__ == '__main__':
    create_example_scenario()
