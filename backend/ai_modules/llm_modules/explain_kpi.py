"""
KPI ì˜í–¥ ë¶„ì„ ìì—°ì–´ ì„¤ëª… ìƒì„± ëª¨ë“ˆ
ì˜¨í†¨ë¡œì§€ ì¶”ì  ê²°ê³¼ â†’ LLM ê¸°ë°˜ ìì—°ì–´ ì„¤ëª… + ê°œì„  ë°©ì•ˆ
"""
import os
from typing import List, Dict, Optional
import json
from pathlib import Path

# OpenAI / Anthropic ì„ íƒ ê°€ëŠ¥
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


class KPIExplainer:
    """
    KPI ì˜í–¥ ë¶„ì„ ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ì‹œìŠ¤í…œ
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = 'gpt-4',
        provider: str = 'openai'
    ):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            model: ëª¨ë¸ ì´ë¦„ ('gpt-4', 'gpt-3.5-turbo', 'claude-3-opus-20240229' ë“±)
            provider: 'openai' ë˜ëŠ” 'anthropic'
        """
        self.provider = provider
        self.model = model

        if provider == 'openai':
            if not OPENAI_AVAILABLE:
                raise ImportError("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install openai")
            self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        elif provider == 'anthropic':
            if not ANTHROPIC_AVAILABLE:
                raise ImportError("Anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install anthropic")
            self.client = Anthropic(api_key=api_key or os.getenv('ANTHROPIC_API_KEY'))
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {provider}")

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = self._load_system_prompt()

    def _load_system_prompt(self) -> str:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        """
        return """ë‹¹ì‹ ì€ APS(Advanced Planning and Scheduling) ì‹œìŠ¤í…œì˜ KPI ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì ëœ KPI ë³€í™”ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³ , ì´í•´í•˜ê¸° ì‰¬ìš´ ìì—°ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

**ì—­í• **:
1. ì¸ê³¼ ì²´ì¸ ë¶„ì„ (ê·¼ë³¸ ì›ì¸ â†’ ì¤‘ê°„ ì´ë²¤íŠ¸ â†’ KPI ì˜í–¥)
2. ë¬¸ì œì˜ ì‹¬ê°ë„ í‰ê°€
3. êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ì œì‹œ
4. ì˜ˆìƒ íš¨ê³¼ ì œì‹œ

**ì„¤ëª… ìŠ¤íƒ€ì¼**:
- ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ
- ìˆ«ìì™€ ì§€í‘œë¥¼ í¬í•¨
- ì¸ê³¼ê´€ê³„ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì„¤ëª…
- í˜„ì¥ ì‹¤ë¬´ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ ì‚¬ìš©

**ì‘ë‹µ í˜•ì‹** (JSON):
{
  "summary": "KPI ë³€í™” ìš”ì•½ (1-2ë¬¸ì¥)",
  "causal_analysis": {
    "root_cause": "ê·¼ë³¸ ì›ì¸",
    "impact_chain": ["ì´ë²¤íŠ¸1 â†’ ì´ë²¤íŠ¸2 â†’ ... â†’ KPI ë³€í™”"],
    "severity_assessment": "ì‹¬ê°ë„ í‰ê°€ (Critical/High/Medium/Low)"
  },
  "detailed_explanation": "ìƒì„¸ ì„¤ëª… (2-3 ë¬¸ë‹¨)",
  "recommendations": [
    {
      "action": "ê°œì„  ì¡°ì¹˜",
      "expected_impact": "ì˜ˆìƒ íš¨ê³¼",
      "priority": "ìš°ì„ ìˆœìœ„ (High/Medium/Low)",
      "implementation_difficulty": "êµ¬í˜„ ë‚œì´ë„ (Easy/Medium/Hard)"
    }
  ],
  "next_steps": ["ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë“¤"]
}
"""

    def explain(
        self,
        kpi_name: str,
        kpi_current: float,
        kpi_target: float,
        causal_chains: List[Dict],
        bottlenecks: Optional[List[Dict]] = None,
        context: Optional[Dict] = None
    ) -> Dict:
        """
        KPI ì˜í–¥ ë¶„ì„ ì„¤ëª… ìƒì„±

        Args:
            kpi_name: KPI ì´ë¦„ (ì˜ˆ: 'ìƒì‚°íš¨ìœ¨', 'ì´ ì§€ì—°ì‹œê°„')
            kpi_current: í˜„ì¬ ê°’
            kpi_target: ëª©í‘œ ê°’
            causal_chains: ì¸ê³¼ ì²´ì¸ ë¦¬ìŠ¤íŠ¸ (kpi_tracer.trace_kpi_impact() ê²°ê³¼)
            bottlenecks: ë³‘ëª© ì„¤ë¹„ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„¤ë¹„ ìˆ˜, ì‘ì—… ìˆ˜ ë“±)

        Returns:
            ì„¤ëª… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = f"""**KPI ë¶„ì„ ìš”ì²­**:

**KPI ì •ë³´**:
- KPI ì´ë¦„: {kpi_name}
- í˜„ì¬ ê°’: {kpi_current}
- ëª©í‘œ ê°’: {kpi_target}
- í¸ì°¨: {kpi_current - kpi_target:.2f} ({'ì´ˆê³¼' if kpi_current > kpi_target else 'ë¯¸ë‹¬'})

**ì¸ê³¼ ì²´ì¸**:
"""

        for i, chain in enumerate(causal_chains, 1):
            user_prompt += f"\n[ì²´ì¸ {i}]\n"
            user_prompt += f"  ì´ë²¤íŠ¸: {chain['event']}\n"
            user_prompt += f"  ì„¤ëª…: {chain['description']}\n"
            user_prompt += f"  ê´€ê³„: {chain['relation']}\n"
            user_prompt += f"  ì‹¬ê°ë„: {chain['severity']:.2f}\n"

            if chain.get('root_causes'):
                user_prompt += f"  ê·¼ë³¸ ì›ì¸:\n"
                for cause in chain['root_causes']:
                    user_prompt += f"    â†’ {cause['description']} (depth: {cause['depth']})\n"
                    if cause.get('sub_causes'):
                        for sub in cause['sub_causes']:
                            user_prompt += f"      â†’ {sub['description']} (depth: {sub['depth']})\n"

        if bottlenecks:
            user_prompt += f"\n**ë³‘ëª© ì„¤ë¹„**:\n"
            for bottleneck in bottlenecks:
                user_prompt += f"  â€¢ {bottleneck['equipment_id']}: ê°€ë™ë¥  {bottleneck['utilization']*100:.1f}% (ì‹¬ê°ë„: {bottleneck['severity']:.2f})\n"

        if context:
            user_prompt += f"\n**í˜„ì¬ ìƒí™©**:\n"
            for key, value in context.items():
                user_prompt += f"  - {key}: {value}\n"

        user_prompt += "\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ KPI ë³€í™”ë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ JSON í˜•ì‹ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”."

        # LLM í˜¸ì¶œ
        if self.provider == 'openai':
            response = self._call_openai(user_prompt)
        else:
            response = self._call_anthropic(user_prompt)

        # JSON íŒŒì‹±
        try:
            result = json.loads(response)
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            result = {
                "summary": response[:200],
                "detailed_explanation": response,
                "recommendations": [],
                "raw_response": response
            }

        return result

    def _call_openai(self, user_prompt: str) -> str:
        """
        OpenAI API í˜¸ì¶œ
        """
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content

    def _call_anthropic(self, user_prompt: str) -> str:
        """
        Anthropic API í˜¸ì¶œ
        """
        response = self.client.messages.create(
            model=self.model,
            max_tokens=2000,
            temperature=0.3,
            system=self.system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.content[0].text

    def format_explanation(self, result: Dict) -> str:
        """
        ì„¤ëª… ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        """
        output = []

        output.append("=" * 80)
        output.append("ğŸ“Š KPI ì˜í–¥ ë¶„ì„ ì„¤ëª…")
        output.append("=" * 80)

        if 'summary' in result:
            output.append(f"\nğŸ’¡ ìš”ì•½:")
            output.append(f"   {result['summary']}")

        if 'causal_analysis' in result:
            analysis = result['causal_analysis']
            output.append(f"\nğŸ” ì¸ê³¼ê´€ê³„ ë¶„ì„:")

            if 'root_cause' in analysis:
                output.append(f"   ê·¼ë³¸ ì›ì¸: {analysis['root_cause']}")

            if 'impact_chain' in analysis:
                output.append(f"   ì˜í–¥ ì²´ì¸:")
                for step in analysis['impact_chain']:
                    output.append(f"      {step}")

            if 'severity_assessment' in analysis:
                output.append(f"   ì‹¬ê°ë„: {analysis['severity_assessment']}")

        if 'detailed_explanation' in result:
            output.append(f"\nğŸ“ ìƒì„¸ ì„¤ëª…:")
            for paragraph in result['detailed_explanation'].split('\n'):
                if paragraph.strip():
                    output.append(f"   {paragraph}")

        if 'recommendations' in result and result['recommendations']:
            output.append(f"\nğŸ’¡ ê°œì„  ë°©ì•ˆ:")
            for i, rec in enumerate(result['recommendations'], 1):
                output.append(f"\n   [{i}] {rec.get('action', 'N/A')}")
                output.append(f"       ì˜ˆìƒ íš¨ê³¼: {rec.get('expected_impact', 'N/A')}")
                output.append(f"       ìš°ì„ ìˆœìœ„: {rec.get('priority', 'N/A')}")
                output.append(f"       êµ¬í˜„ ë‚œì´ë„: {rec.get('implementation_difficulty', 'N/A')}")

        if 'next_steps' in result and result['next_steps']:
            output.append(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
            for step in result['next_steps']:
                output.append(f"   â€¢ {step}")

        output.append("\n" + "=" * 80)

        return "\n".join(output)


def demo_with_mock_response():
    """
    API ì—†ì´ ë°ëª¨ ì‹¤í–‰ (ë¯¸ë¦¬ ì •ì˜ëœ ì‘ë‹µ ì‚¬ìš©)
    """
    print("=" * 80)
    print("ğŸ­ KPI ì„¤ëª… ë°ëª¨ (Mock ì‘ë‹µ)")
    print("=" * 80)

    # Mock ì¸ê³¼ ì²´ì¸ (kpi_tracer ì˜ˆì œ ê²°ê³¼ì™€ ë™ì¼)
    causal_chains = [
        {
            'event': 'Event_E003',
            'relation': 'decreases',
            'description': 'ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°',
            'severity': 0.8,
            'root_causes': [
                {
                    'cause': 'Event_E002',
                    'relation': 'leadsTo',
                    'description': 'ì‘ì—… ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (í‰ê·  45ë¶„)',
                    'depth': 1,
                    'sub_causes': [
                        {
                            'cause': 'Event_E001',
                            'relation': 'causes',
                            'description': 'MC001 ì„¤ë¹„ ê³¼ë¶€í•˜ ë°œìƒ (ê°€ë™ë¥  95%)',
                            'depth': 2,
                            'sub_causes': []
                        }
                    ]
                }
            ]
        }
    ]

    bottlenecks = [
        {
            'equipment_id': 'MC001',
            'utilization': 0.95,
            'severity': 0.5
        }
    ]

    # Mock ì‘ë‹µ (ì‹¤ì œ GPT-4 ì‘ë‹µ ì˜ˆì‹œ)
    mock_response = {
        "summary": "MC001 ì„¤ë¹„ì˜ ê³¼ë¶€í•˜(ê°€ë™ë¥  95%)ë¡œ ì¸í•´ ì‘ì—… ëŒ€ê¸°ì‹œê°„ì´ í‰ê·  45ë¶„ ì¦ê°€í–ˆê³ , ì´ë¡œ ì¸í•´ ì „ì²´ ìƒì‚° ì¼ì •ì´ ì§€ì—°ë˜ì–´ ìƒì‚°íš¨ìœ¨ KPIê°€ ëª©í‘œ(85%) ëŒ€ë¹„ 13% ë‚®ì€ 72%ë¡œ í•˜ë½í–ˆìŠµë‹ˆë‹¤.",
        "causal_analysis": {
            "root_cause": "MC001 ì„¤ë¹„ ê³¼ë¶€í•˜ (ê°€ë™ë¥  95%)",
            "impact_chain": [
                "MC001 ê³¼ë¶€í•˜ ë°œìƒ",
                "â†’ ì‘ì—… ëŒ€ê¸° ì‹œê°„ 45ë¶„ ì¦ê°€",
                "â†’ ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°",
                "â†’ ìƒì‚°íš¨ìœ¨ KPI 13% í•˜ë½ (85% â†’ 72%)"
            ],
            "severity_assessment": "High"
        },
        "detailed_explanation": """MC001 ì„¤ë¹„ì˜ ê³¼ë¶€í•˜ ìƒíƒœê°€ ì „ì²´ ìƒì‚° ì‹œìŠ¤í…œì— ì—°ì‡„ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.

ì²«ì§¸, MC001ì˜ ê°€ë™ë¥ ì´ 95%ë¡œ ë§¤ìš° ë†’ì•„ ìƒˆë¡œìš´ ì‘ì—…ì´ í• ë‹¹ë  ë•Œë§ˆë‹¤ ê¸´ ëŒ€ê¸° ì‹œê°„ì´ ë°œìƒí•©ë‹ˆë‹¤. í‰ê·  45ë¶„ì˜ ëŒ€ê¸° ì‹œê°„ì€ í›„ì† ê³µì •ì—ë„ ì˜í–¥ì„ ë¯¸ì³ ì „ì²´ ìƒì‚° íë¦„ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ë‘˜ì§¸, ì´ëŸ¬í•œ ì§€ì—°ì´ ëˆ„ì ë˜ë©´ì„œ ì „ì²´ ìƒì‚° ì¼ì •ì´ ê³„íš ëŒ€ë¹„ ë’¤ì²˜ì§€ê³  ìˆìœ¼ë©°, ê²°ê³¼ì ìœ¼ë¡œ ìƒì‚°íš¨ìœ¨ KPIê°€ ëª©í‘œ 85% ëŒ€ë¹„ 13%p ë‚®ì€ 72%ë¥¼ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¬ê°í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ì €í•˜ë¡œ, ì¦‰ê°ì ì¸ ê°œì„  ì¡°ì¹˜ê°€ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤.

í˜„ì¬ MC002 ì„¤ë¹„ì˜ ê°€ë™ë¥ ì´ 65%ë¡œ ì—¬ìœ ê°€ ìˆëŠ” ì ì„ ê³ ë ¤í•˜ë©´, ì‘ì—… ì¬ë°°ë¶„ì„ í†µí•œ ë¶€í•˜ ë¶„ì‚°ì´ íš¨ê³¼ì ì¼ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.""",
        "recommendations": [
            {
                "action": "MC001ì˜ ì¼ë¶€ ì‘ì—…ì„ MC002ë¡œ ì¬ë°°ì¹˜ (ë¶€í•˜ ë¶„ì‚°)",
                "expected_impact": "MC001 ê°€ë™ë¥  95% â†’ 85%, ëŒ€ê¸° ì‹œê°„ 45ë¶„ â†’ 20ë¶„ ê°ì†Œ, ìƒì‚°íš¨ìœ¨ 72% â†’ 80% ê°œì„ ",
                "priority": "High",
                "implementation_difficulty": "Easy"
            },
            {
                "action": "MC001 ì˜ˆì§€ë³´ì „ ì‹¤ì‹œ (ê³ ì¥ ë¦¬ìŠ¤í¬ ê°ì†Œ)",
                "expected_impact": "ì„¤ë¹„ ì‹ ë¢°ì„± í–¥ìƒ, ë¹„ê³„íš ì¤‘ë‹¨ 50% ê°ì†Œ",
                "priority": "High",
                "implementation_difficulty": "Medium"
            },
            {
                "action": "ê¸´ê¸‰ ì‘ì—…ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ ì¬ì¡°ì •",
                "expected_impact": "ì¤‘ìš” ì‘ì—… ë‚©ê¸° ì¤€ìˆ˜ìœ¨ 75% â†’ 90% ê°œì„ ",
                "priority": "Medium",
                "implementation_difficulty": "Easy"
            },
            {
                "action": "ë°°ì¹˜ í¬ê¸° ìµœì í™” (ì‘ì€ ë°°ì¹˜ í†µí•©)",
                "expected_impact": "ê³µì • ì „í™˜ íšŸìˆ˜ 30% ê°ì†Œ, Setup ì‹œê°„ ì ˆê°",
                "priority": "Medium",
                "implementation_difficulty": "Medium"
            }
        ],
        "next_steps": [
            "MC001ì˜ í˜„ì¬ ì‘ì—… ëª©ë¡ ê²€í†  ë° MC002ë¡œ ì´ì „ ê°€ëŠ¥í•œ ì‘ì—… ì„ ë³„",
            "ì‘ì—… ì¬ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ì˜ˆìƒ íš¨ê³¼ ê²€ì¦)",
            "MC001 ì˜ˆì§€ë³´ì „ ì¼ì • ìˆ˜ë¦½ (ë‹¤ìŒ ì£¼ ë‚´)",
            "ê¸´ê¸‰ ì‘ì—… ìš°ì„ ìˆœìœ„ ê·œì¹™ ì¬ê²€í†  ë° ìˆ˜ì •",
            "1ì£¼ í›„ KPI ì¬ì¸¡ì • ë° íš¨ê³¼ í‰ê°€"
        ]
    }

    # Mock ê²°ê³¼ ì¶œë ¥
    explainer = KPIExplainer.__new__(KPIExplainer)
    formatted = explainer.format_explanation(mock_response)
    print(formatted)

    print("\nğŸ’¾ Mock ì‘ë‹µ ì €ì¥ ì¤‘...")
    output_path = Path(__file__).parent / 'kpi_explanation_example.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(mock_response, f, indent=2, ensure_ascii=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")


def integrated_demo():
    """
    kpi_tracer + explain_kpi í†µí•© ë°ëª¨
    """
    print("\n" + "=" * 80)
    print("ğŸ”— í†µí•© ë°ëª¨: KPI ì¶”ì  + ì„¤ëª… ìƒì„±")
    print("=" * 80)

    # Step 1: KPI ì¶”ì 
    print("\n[Step 1] KPI ì˜í–¥ ë¶„ì„ (ì˜¨í†¨ë¡œì§€ ì¶”ì )...")
    try:
        from kpi_tracer import create_example_scenario
        tracer, causal_chains, bottlenecks = create_example_scenario()
        print("âœ… ì¸ê³¼ ì²´ì¸ ì¶”ì  ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  kpi_tracer ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("   Mock ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        causal_chains = [
            {
                'event': 'Event_E003',
                'description': 'ì „ì²´ ìƒì‚° ì¼ì • ì§€ì—°',
                'relation': 'decreases',
                'severity': 0.8,
                'root_causes': []
            }
        ]
        bottlenecks = [{'equipment_id': 'MC001', 'utilization': 0.95, 'severity': 0.5}]

    # Step 2: LLM ì„¤ëª… ìƒì„±
    print("\n[Step 2] LLM ê¸°ë°˜ ìì—°ì–´ ì„¤ëª… ìƒì„±...")
    print("   (API í‚¤ê°€ ì—†ìœ¼ë¯€ë¡œ Mock ì‘ë‹µ ì‚¬ìš©)")

    demo_with_mock_response()


if __name__ == '__main__':
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == 'integrated':
        # í†µí•© ë°ëª¨ ì‹¤í–‰
        integrated_demo()
    else:
        # ê¸°ë³¸ ë°ëª¨ ì‹¤í–‰
        print("""
ì‚¬ìš©ë²•:
  1. Mock ì‘ë‹µìœ¼ë¡œ ë°ëª¨ ì‹¤í–‰:
     python explain_kpi.py

  2. í†µí•© ë°ëª¨ (kpi_tracer + explain_kpi):
     python explain_kpi.py integrated

  3. ì‹¤ì œ API ì‚¬ìš©:
     export OPENAI_API_KEY=your-api-key  # ë˜ëŠ” ANTHROPIC_API_KEY
     python -c "
from explain_kpi import KPIExplainer

explainer = KPIExplainer(model='gpt-4', provider='openai')

causal_chains = [...]  # kpi_tracer ê²°ê³¼
bottlenecks = [...]

result = explainer.explain(
    kpi_name='ìƒì‚°íš¨ìœ¨',
    kpi_current=72.0,
    kpi_target=85.0,
    causal_chains=causal_chains,
    bottlenecks=bottlenecks
)

print(explainer.format_explanation(result))
"
        """)

        demo_with_mock_response()
