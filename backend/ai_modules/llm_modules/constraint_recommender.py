"""
LLM ê¸°ë°˜ ì œì•½ì¡°ê±´ ì¶”ì²œ ëª¨ë“ˆ
í˜„ì¥ ë¬¸ì œ ì„¤ëª… â†’ AIê°€ ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆ ìë™ ì¶”ì²œ
"""
import os
from typing import List, Dict, Optional
import json
from pathlib import Path

# OpenAI / Anthropic ì„ íƒ ê°€ëŠ¥
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


class ConstraintRecommender:
    """
    LLM ê¸°ë°˜ ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆ ì¶”ì²œ ì‹œìŠ¤í…œ
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = 'gpt-4',
        provider: str = 'openai'
    ):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            model: ëª¨ë¸ ì´ë¦„ ('gpt-4', 'gpt-3.5-turbo', 'claude-3-opus-20240229' ë“±)
            provider: 'openai' ë˜ëŠ” 'anthropic'
        """
        self.provider = provider
        self.model = model

        if provider == 'openai':
            if not OPENAI_AVAILABLE:
                raise ImportError("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install openai")
            self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        elif provider == 'anthropic':
            if not ANTHROPIC_AVAILABLE:
                raise ImportError("Anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install anthropic")
            self.client = Anthropic(api_key=api_key or os.getenv('ANTHROPIC_API_KEY'))
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {provider}")

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = self._load_system_prompt()

    def _load_system_prompt(self) -> str:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        """
        return """ë‹¹ì‹ ì€ APS(Advanced Planning and Scheduling) ì‹œìŠ¤í…œì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œì¡° í˜„ì¥ì˜ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³ , ìµœì ì˜ ì œì•½ì¡°ê±´(Constraints)ê³¼ ê°œì„  ë°©ì•ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.

**ì—­í• **:
1. ì‚¬ìš©ìê°€ ì„¤ëª…í•œ í˜„ì¥ ë¬¸ì œë¥¼ ë¶„ì„
2. ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ íŒŒì•…
3. ì ì ˆí•œ ì œì•½ì¡°ê±´ ì¶”ì²œ (ë‚©ê¸° ì œì•½, ì„¤ë¹„ ì œì•½, ì‹œê°„ ì œì•½ ë“±)
4. êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ì œì‹œ
5. ì˜ˆìƒ íš¨ê³¼ ë° ì£¼ì˜ì‚¬í•­ ì•ˆë‚´

**ì œì•½ì¡°ê±´ ìœ í˜•**:
- Due Date Constraint: ë‚©ê¸° ì œì•½
- Machine Constraint: ì„¤ë¹„ ì œì•½ (ì‚¬ìš© ë¶ˆê°€ ì‹œê°„, ëŠ¥ë ¥ ì œí•œ ë“±)
- Precedence Constraint: ì„ í–‰ ì‘ì—… ì œì•½
- Resource Constraint: ìì› ì œì•½ (ì¸ë ¥, ìì¬ ë“±)
- Time Window Constraint: ì‹œê°„ëŒ€ ì œì•½
- Setup Time Constraint: ì„¤ì • ì‹œê°„ ì œì•½

**ì‘ë‹µ í˜•ì‹** (JSON):
{
  "problem_analysis": "ë¬¸ì œ ë¶„ì„ ë‚´ìš©",
  "root_cause": "ê·¼ë³¸ ì›ì¸",
  "recommendations": [
    {
      "constraint_type": "ì œì•½ì¡°ê±´ ìœ í˜•",
      "constraint_description": "ì œì•½ì¡°ê±´ ì„¤ëª…",
      "implementation": "êµ¬í˜„ ë°©ë²•",
      "expected_impact": "ì˜ˆìƒ íš¨ê³¼",
      "priority": "ìš°ì„ ìˆœìœ„ (High/Medium/Low)"
    }
  ],
  "additional_suggestions": ["ì¶”ê°€ ì œì•ˆ ì‚¬í•­ë“¤"],
  "warnings": ["ì£¼ì˜ì‚¬í•­ë“¤"]
}
"""

    def recommend(
        self,
        problem_description: str,
        context: Optional[Dict] = None
    ) -> Dict:
        """
        ë¬¸ì œ ì„¤ëª… â†’ ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆ ì¶”ì²œ

        Args:
            problem_description: í˜„ì¥ ë¬¸ì œ ì„¤ëª…
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„¤ë¹„ ìˆ˜, ì‘ì—… ìˆ˜, í˜„ì¬ KPI ë“±)

        Returns:
            ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = f"""**í˜„ì¥ ë¬¸ì œ**:
{problem_description}
"""

        if context:
            user_prompt += f"\n**í˜„ì¬ ìƒí™©**:\n"
            for key, value in context.items():
                user_prompt += f"- {key}: {value}\n"

        user_prompt += "\nìœ„ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”."

        # LLM í˜¸ì¶œ
        if self.provider == 'openai':
            response = self._call_openai(user_prompt)
        else:
            response = self._call_anthropic(user_prompt)

        # JSON íŒŒì‹±
        try:
            result = json.loads(response)
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            result = {
                "problem_analysis": response,
                "recommendations": [],
                "raw_response": response
            }

        return result

    def _call_openai(self, user_prompt: str) -> str:
        """
        OpenAI API í˜¸ì¶œ
        """
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content

    def _call_anthropic(self, user_prompt: str) -> str:
        """
        Anthropic API í˜¸ì¶œ
        """
        response = self.client.messages.create(
            model=self.model,
            max_tokens=2000,
            temperature=0.3,
            system=self.system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.content[0].text

    def format_recommendations(self, result: Dict) -> str:
        """
        ì¶”ì²œ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        """
        output = []

        output.append("=" * 80)
        output.append("ğŸ¤– AI ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆ ì¶”ì²œ")
        output.append("=" * 80)

        if 'problem_analysis' in result:
            output.append(f"\nğŸ“Š ë¬¸ì œ ë¶„ì„:")
            output.append(f"   {result['problem_analysis']}")

        if 'root_cause' in result:
            output.append(f"\nğŸ” ê·¼ë³¸ ì›ì¸:")
            output.append(f"   {result['root_cause']}")

        if 'recommendations' in result and result['recommendations']:
            output.append(f"\nğŸ’¡ ì¶”ì²œ ì œì•½ì¡°ê±´ ë° ê°œì„  ë°©ì•ˆ:")
            for i, rec in enumerate(result['recommendations'], 1):
                output.append(f"\n   [{i}] {rec.get('constraint_type', 'N/A')} (ìš°ì„ ìˆœìœ„: {rec.get('priority', 'N/A')})")
                output.append(f"       ì„¤ëª…: {rec.get('constraint_description', 'N/A')}")
                output.append(f"       êµ¬í˜„: {rec.get('implementation', 'N/A')}")
                output.append(f"       ì˜ˆìƒ íš¨ê³¼: {rec.get('expected_impact', 'N/A')}")

        if 'additional_suggestions' in result and result['additional_suggestions']:
            output.append(f"\nğŸ“ ì¶”ê°€ ì œì•ˆ:")
            for suggestion in result['additional_suggestions']:
                output.append(f"   â€¢ {suggestion}")

        if 'warnings' in result and result['warnings']:
            output.append(f"\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
            for warning in result['warnings']:
                output.append(f"   â€¢ {warning}")

        output.append("\n" + "=" * 80)

        return "\n".join(output)


# í”„ë¡¬í”„íŠ¸ ì˜ˆì œ ì €ì¥
EXAMPLE_PROMPTS = {
    "bottleneck_cip": {
        "problem": "CIP(Clean In Place) ì‹œê°„ì´ ë³‘ëª©ì´ ë˜ì–´ ì „ì²´ ìƒì‚°ì„±ì´ ì €í•˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. CIPëŠ” ê³µì • ê°„ ì„¤ë¹„ ì„¸ì²™ ì‘ì—…ìœ¼ë¡œ í‰ê·  30ë¶„ ì†Œìš”ë˜ë©°, í•˜ë£¨ í‰ê·  8íšŒ ë°œìƒí•©ë‹ˆë‹¤.",
        "context": {
            "ì„¤ë¹„ ìˆ˜": 5,
            "ì¼ì¼ ì‘ì—… ìˆ˜": 25,
            "CIP í‰ê·  ì‹œê°„": "30ë¶„",
            "CIP ë¹ˆë„": "8íšŒ/ì¼",
            "ì´ CIP ì‹œê°„": "240ë¶„/ì¼"
        }
    },
    "machine_overload": {
        "problem": "MC001 ì„¤ë¹„ê°€ ê³¼ë¶€í•˜ ìƒíƒœ(ê°€ë™ë¥  95%)ì´ë©°, ìì£¼ ê³ ì¥ì´ ë°œìƒí•©ë‹ˆë‹¤. ë°˜ë©´ MC005ëŠ” ì €ê°€ë™(ê°€ë™ë¥  60%) ìƒíƒœì…ë‹ˆë‹¤.",
        "context": {
            "MC001 ê°€ë™ë¥ ": "95%",
            "MC005 ê°€ë™ë¥ ": "60%",
            "MC001 ê³ ì¥ ë¹ˆë„": "ì›” 3íšŒ",
            "í‰ê·  ìˆ˜ë¦¬ ì‹œê°„": "4ì‹œê°„"
        }
    },
    "tardiness_high": {
        "problem": "ë‚©ê¸° ì§€ì—°ì´ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤. íŠ¹íˆ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê¸´ê¸‰ ì˜¤ë”ì˜ ë‚©ê¸° ì¤€ìˆ˜ìœ¨ì´ 75%ì— ë¶ˆê³¼í•©ë‹ˆë‹¤.",
        "context": {
            "ì „ì²´ ë‚©ê¸° ì¤€ìˆ˜ìœ¨": "82%",
            "ê¸´ê¸‰ ì˜¤ë” ë‚©ê¸° ì¤€ìˆ˜ìœ¨": "75%",
            "í‰ê·  ì§€ì—° ì‹œê°„": "48ì‹œê°„",
            "ê¸´ê¸‰ ì˜¤ë” ë¹„ìœ¨": "20%"
        }
    },
    "quality_issue": {
        "problem": "3ì£¼ì°¨ë§ˆë‹¤ í’ˆì§ˆ ë¶ˆëŸ‰ë¥ ì´ ê¸‰ì¦í•©ë‹ˆë‹¤(3.5% â†’ 4.5%). íŒ¨í„´ì„ ë³´ë©´ ê³µêµ¬ ë§ˆëª¨ì™€ ì—°ê´€ì´ ìˆëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
        "context": {
            "í‰ê·  ë¶ˆëŸ‰ë¥ ": "3.5%",
            "í”¼í¬ ë¶ˆëŸ‰ë¥ ": "4.5%",
            "ë¶ˆëŸ‰ ì£¼ê¸°": "3ì£¼",
            "í˜„ì¬ ê³µêµ¬ êµì²´ ì£¼ê¸°": "4ì£¼"
        }
    }
}


def save_example_prompts():
    """
    ì˜ˆì œ í”„ë¡¬í”„íŠ¸ ì €ì¥
    """
    output_path = Path(__file__).parent / 'example_prompts.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(EXAMPLE_PROMPTS, f, indent=2, ensure_ascii=False)
    print(f"âœ… ì˜ˆì œ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")


def demo_without_api():
    """
    API ì—†ì´ ë°ëª¨ ì‹¤í–‰ (ë¯¸ë¦¬ ì •ì˜ëœ ì‘ë‹µ ì‚¬ìš©)
    """
    print("=" * 80)
    print("ğŸ­ LLM ì œì•½ì¡°ê±´ ì¶”ì²œ ë°ëª¨ (Mock ì‘ë‹µ)")
    print("=" * 80)

    # Mock ì‘ë‹µ (ì‹¤ì œ GPT-4 ì‘ë‹µ ì˜ˆì‹œ)
    mock_response = {
        "problem_analysis": "CIP ì‹œê°„ì´ í•˜ë£¨ 240ë¶„(4ì‹œê°„)ìœ¼ë¡œ ì „ì²´ ìƒì‚° ì‹œê°„ì˜ ì•½ 20%ë¥¼ ì°¨ì§€í•˜ê³  ìˆì–´ ë³‘ëª©ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë¹ˆë²ˆí•œ CIPë¡œ ì¸í•´ ì„¤ë¹„ ê°€ë™ë¥ ì´ ì €í•˜ë˜ê³  ì „ì²´ Makespanì´ ì¦ê°€í•˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.",
        "root_cause": "1) ì†Œê·œëª¨ ë°°ì¹˜ë¡œ ì¸í•œ ë¹ˆë²ˆí•œ ê³µì • ì „í™˜, 2) CIP ì‹œê°„ ìµœì í™” ë¶€ì¡±, 3) ì„¤ë¹„ ê°„ ì‘ì—… ë°°ë¶„ ë¶ˆê· í˜•ìœ¼ë¡œ ì¸í•œ CIP ì¤‘ë³µ",
        "recommendations": [
            {
                "constraint_type": "Setup Time Constraint",
                "constraint_description": "ê³µì •ê°„ ì„¤ì •ì‹œê°„(CIP í¬í•¨) 10% ê°ì†Œ ì œì•½ ì¶”ê°€",
                "implementation": "APS ìŠ¤ì¼€ì¤„ë§ ì‹œ ë™ì¼ í’ˆëª©/ê³µì •ì„ ì—°ì† ë°°ì¹˜í•˜ì—¬ CIP ë¹ˆë„ ê°ì†Œ. ë°°ì¹˜ í¬ê¸°ë¥¼ 30% ì¦ê°€ì‹œì¼œ ê³µì • ì „í™˜ íšŸìˆ˜ ê°ì†Œ.",
                "expected_impact": "CIP ì‹œê°„ 240ë¶„ â†’ 190ë¶„ (21% ê°ì†Œ), Makespan ì•½ 50ë¶„ ë‹¨ì¶•",
                "priority": "High"
            },
            {
                "constraint_type": "Machine Constraint",
                "constraint_description": "CIP ì „ìš© ì‹œê°„ëŒ€ ì§€ì • ì œì•½",
                "implementation": "11:30-12:00, 17:30-18:00ì„ CIP ì „ìš© ì‹œê°„ëŒ€ë¡œ ì§€ì •í•˜ì—¬ ì§‘ì¤‘ ì²˜ë¦¬. í•´ë‹¹ ì‹œê°„ëŒ€ì—ëŠ” ì‹ ê·œ ì‘ì—… ì‹œì‘ ê¸ˆì§€.",
                "expected_impact": "CIP ëŒ€ê¸° ì‹œê°„ ê°ì†Œ, ì„¤ë¹„ ê°€ë™ë¥  3-5% í–¥ìƒ",
                "priority": "Medium"
            },
            {
                "constraint_type": "Precedence Constraint",
                "constraint_description": "í’ˆëª© ìœ ì‚¬ì„± ê¸°ë°˜ ì‘ì—… ìˆœì„œ ì œì•½",
                "implementation": "ë™ì¼ ê³„ì—´ í’ˆëª©ì€ ì—°ì† ìŠ¤ì¼€ì¤„ë§. ì˜ˆ: í”„ë ˆì„ A â†’ í”„ë ˆì„ B â†’ ë¸Œë¼ì¼“ ìˆœì„œë¡œ ë°°ì¹˜í•˜ì—¬ CIP ê°•ë„ ì™„í™”.",
                "expected_impact": "CIP í‰ê·  ì‹œê°„ 30ë¶„ â†’ 25ë¶„ (ê°„ì†Œí™”ëœ ì„¸ì²™)",
                "priority": "High"
            }
        ],
        "additional_suggestions": [
            "CIP ìë™í™” ì„¤ë¹„ ë„ì… ê²€í†  (íˆ¬ìë¹„ìš© vs íš¨ê³¼ ë¶„ì„ í•„ìš”)",
            "ë°°ì¹˜ í¬ê¸° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì ìš© (RL ê¸°ë°˜ ë™ì  ë°°ì¹˜ ì¡°ì •)",
            "ì„¤ë¹„ ì „ìš©í™” ê³ ë ¤ (MC001: í”„ë ˆì„ ì „ìš©, MC002: ë¸Œë¼ì¼“ ì „ìš© ë“±)"
        ],
        "warnings": [
            "ë°°ì¹˜ í¬ê¸° ì¦ê°€ ì‹œ ì¬ê³  ë¹„ìš© ì¦ê°€ ê°€ëŠ¥ì„± ìˆìŒ",
            "CIP ì‹œê°„ ë‹¨ì¶• ì‹œ í’ˆì§ˆ ë¬¸ì œ ë°œìƒ ìœ„í—˜ â†’ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš”",
            "ì„¤ë¹„ ì „ìš©í™” ì‹œ ìœ ì—°ì„± ê°ì†Œ â†’ ê¸´ê¸‰ ì˜¤ë” ëŒ€ì‘ ëŠ¥ë ¥ ì €í•˜ ê°€ëŠ¥"
        ]
    }

    # Mock ê²°ê³¼ ì¶œë ¥
    recommender = ConstraintRecommender.__new__(ConstraintRecommender)
    formatted = recommender.format_recommendations(mock_response)
    print(formatted)

    print("\nğŸ’¾ ì˜ˆì œ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì¤‘...")
    save_example_prompts()


if __name__ == '__main__':
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == 'demo':
        # API ì—†ì´ ë°ëª¨ ì‹¤í–‰
        demo_without_api()
    else:
        print("""
ì‚¬ìš©ë²•:
  1. API ì—†ì´ ë°ëª¨ ì‹¤í–‰:
     python constraint_recommender.py demo

  2. ì‹¤ì œ API ì‚¬ìš©:
     export OPENAI_API_KEY=your-api-key  # ë˜ëŠ” ANTHROPIC_API_KEY
     python -c "
from constraint_recommender import ConstraintRecommender

recommender = ConstraintRecommender(model='gpt-4', provider='openai')
result = recommender.recommend(
    problem_description='CIP ì‹œê°„ì´ ë³‘ëª©ì´ì•¼',
    context={'CIP í‰ê·  ì‹œê°„': '30ë¶„', 'CIP ë¹ˆë„': '8íšŒ/ì¼'}
)
print(recommender.format_recommendations(result))
"
        """)
